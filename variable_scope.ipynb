{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基礎から実践 TensorFlow 重み共有\n",
    "TensorFlow での重み共有と tf.variable_scope() を動かしてみるノートブックです。\n",
    "[公式：Variables](https://www.tensorflow.org/programmers_guide/variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_variables():\n",
    "    print('\\n'.join([v.name for v in tf.global_variables()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本： Variable, variable_scope, get_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable と get_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable:0\n",
      "variable_1:0\n",
      "variable_2:0\n"
     ]
    }
   ],
   "source": [
    "# variable_scope 無しでの Variable/get_variable\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    v_a = tf.Variable(tf.random_uniform(shape=[2, 3]), name='variable')  # -> variable:0\n",
    "    v_b = tf.Variable(tf.random_uniform(shape=[2, 3]), name='variable')  # -> variable_1:0\n",
    "    v_c = tf.get_variable('variable', shape=[2, 3])  # -> variable_2:0\n",
    "    # v_d = tf.get_variable('variable', shape=[2, 3])  # -> ERROR\n",
    "    show_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable_scope で変数を階層化・共有する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoge/variable:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    with tf.variable_scope('hoge'):\n",
    "        v_a = tf.get_variable('variable', shape=[2, 3])  # -> hoge/variable_2:0\n",
    "        # v_b = tf.get_variable('variable', shape=[2, 3])  #-> ERROR\n",
    "        \n",
    "    with tf.variable_scope('hoge', reuse=True):  # 変数を共有\n",
    "        v_c = tf.get_variable('variable', shape=[2, 3])  # -> hoge/variable_2:0 共有した！\n",
    "        # v_d = tf.get_variable('variable_new', shape=[2, 3])  # -> ERROR\n",
    "        show_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable_scope の reuse option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reuse_none/variable:0\n",
      "reuse_true/variable:0\n",
      "auto_reuse/variable:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    with tf.variable_scope('reuse_none', reuse=None):  # 再利用しない。デフォルト。\n",
    "        v_none_a = tf.get_variable('variable', shape=[2, 3])  # -> reuse_none/variable:0\n",
    "        # v_none_b = tf.get_variable('variable', shape=[2, 3])  # -> ERROR\n",
    "\n",
    "    with tf.variable_scope('reuse_true', reuse=None):  # reuse=True だと変数の作成ができないので予め reuse=None で作る\n",
    "        v_true_a = tf.get_variable('variable', shape=[2, 3])  # -> reuse_true/variable:0\n",
    "    with tf.variable_scope('reuse_true', reuse=True):\n",
    "        v_true_a = tf.get_variable('variable', shape=[2, 3])  # -> reuse_true/variable:0\n",
    "        # v_true_b = tf.get_variable('variable_b', shape=[2, 3])  # -> ERROR\n",
    "\n",
    "    with tf.variable_scope('auto_reuse', reuse=tf.AUTO_REUSE):  # 無ければ作成、あれば再利用。便利だけど危険。\n",
    "        v_none_a = tf.get_variable('variable', shape=[2, 3])  # -> auto_reuse/variable:0\n",
    "        v_none_b = tf.get_variable('variable', shape=[2, 3])  # -> auto_reuse/variable:0\n",
    "\n",
    "    show_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reuse_true/variable:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    with tf.variable_scope('reuse_true') as scope:\n",
    "        # reuse=None (default)\n",
    "        v_true_a = tf.get_variable('variable', shape=[2, 3])  # -> reuse_true/variable:0\n",
    "\n",
    "        scope.reuse_variables()\n",
    "        # reuse=True\n",
    "        v_true_a = tf.get_variable('variable', shape=[2, 3])  # -> reuse_true/variable:0\n",
    "        # v_true_b = tf.get_variable('variable_b', shape=[2, 3])  # -> ERROR\n",
    "    show_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reuse option の継承"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reuse_none: False\n",
      "reuse_none/reuse_none: False\n",
      "reuse_none/reuse_true: True\n",
      "reuse_none/auto_reuse: _ReuseMode.AUTO_REUSE\n",
      "reuse_true: True\n",
      "reuse_true/reuse_none: True\n",
      "reuse_true/reuse_true: True\n",
      "reuse_true/auto_reuse: _ReuseMode.AUTO_REUSE\n",
      "auto_reuse: _ReuseMode.AUTO_REUSE\n",
      "auto_reuse/reuse_none: _ReuseMode.AUTO_REUSE\n",
      "auto_reuse/reuse_true: True\n",
      "auto_reuse/auto_reuse: _ReuseMode.AUTO_REUSE\n"
     ]
    }
   ],
   "source": [
    "def show_reuse(scope):\n",
    "    print('{}: {}'.format(scope.name, scope.reuse))\n",
    "    \n",
    "with tf.variable_scope('reuse_none', reuse=None) as outer_scope:\n",
    "    show_reuse(outer_scope)\n",
    "    with tf.variable_scope('reuse_none', reuse=None) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('reuse_true', reuse=True) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('auto_reuse', reuse=tf.AUTO_REUSE) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "\n",
    "with tf.variable_scope('reuse_true', reuse=True) as outer_scope:\n",
    "    show_reuse(outer_scope)\n",
    "    with tf.variable_scope('reuse_none', reuse=None) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('reuse_true', reuse=True) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('auto_reuse', reuse=tf.AUTO_REUSE) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "\n",
    "with tf.variable_scope('auto_reuse', reuse=tf.AUTO_REUSE) as outer_scope:\n",
    "    show_reuse(outer_scope)\n",
    "    with tf.variable_scope('reuse_none', reuse=None) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('reuse_true', reuse=True) as inner_scope:\n",
    "        show_reuse(inner_scope)\n",
    "    with tf.variable_scope('auto_reuse', reuse=tf.AUTO_REUSE) as inner_scope:\n",
    "        show_reuse(inner_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実践重み共有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_same_outputs(tensor1, tensor2, sess):\n",
    "    # ２つのテンソルの値が同じかを返します\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result1, result2 = sess.run([tensor1, tensor2])\n",
    "    return result1.tolist() == result2.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単純なフィードフォワードネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークの作成を部品化\n",
    "def feed_forward(inputs):\n",
    "    d1 = tf.layers.dense(inputs, 20, name='dense_a')\n",
    "    d2 = tf.layers.dense(d1, 30, name='dense_b')\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared: False\n",
      "feed_forward_x/dense_a/kernel:0\n",
      "feed_forward_x/dense_a/bias:0\n",
      "feed_forward_x/dense_b/kernel:0\n",
      "feed_forward_x/dense_b/bias:0\n",
      "feed_forward_y/dense_a/kernel:0\n",
      "feed_forward_y/dense_a/bias:0\n",
      "feed_forward_y/dense_b/kernel:0\n",
      "feed_forward_y/dense_b/bias:0\n"
     ]
    }
   ],
   "source": [
    "# 独立したネットワークを２つ作る例\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    inputs = tf.ones(shape=[2, 3])\n",
    "    with tf.variable_scope('feed_forward_x'):\n",
    "        outputs_x = feed_forward(inputs)\n",
    "    with tf.variable_scope('feed_forward_y'):\n",
    "        outputs_y = feed_forward(inputs)\n",
    "    print('shared: {}'.format(has_same_outputs(outputs_x, outputs_y, sess)))\n",
    "    show_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared: True\n",
      "feed_forward_shared/dense_a/kernel:0\n",
      "feed_forward_shared/dense_a/bias:0\n",
      "feed_forward_shared/dense_b/kernel:0\n",
      "feed_forward_shared/dense_b/bias:0\n"
     ]
    }
   ],
   "source": [
    "# 重みを共有した実質一つのネットワークを２つ作る例\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    inputs = tf.ones(shape=[2, 3])\n",
    "    with tf.variable_scope('feed_forward_shared') as scope:\n",
    "        outputs_x = feed_forward(inputs)\n",
    "        scope.reuse_variables()\n",
    "        outputs_y = feed_forward(inputs)\n",
    "    print('shared: {}'.format(has_same_outputs(outputs_x, outputs_y, sess)))\n",
    "    show_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq のデコーダを学習時と生成時で分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 302  143 1909 1909 1909 1909 1909 1909]\n",
      " [ 302  143 1909 1909 1909 1909 1909 1909]]\n",
      "[[1120 2573 2918 2455 2455 2316 2316 2316]\n",
      " [1120 2573 2918 2455 2455 2316 2316 2316]]\n",
      "embedding:0\n",
      "encoder/cell/gates/kernel:0\n",
      "encoder/cell/gates/bias:0\n",
      "encoder/cell/candidate/kernel:0\n",
      "encoder/cell/candidate/bias:0\n",
      "decoder/decoder/cell/gates/kernel:0\n",
      "decoder/decoder/cell/gates/bias:0\n",
      "decoder/decoder/cell/candidate/kernel:0\n",
      "decoder/decoder/cell/candidate/bias:0\n",
      "decoder/decoder/out_layer/kernel:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab_size = 3000\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "batch_size = 2\n",
    "beam_width = 2\n",
    "max_len = 8\n",
    "decoder_scope = 'decoder'\n",
    "cell_name = 'cell'\n",
    "out_layer_name = 'out_layer'\n",
    "\n",
    "def create_encoder(inputs, inputs_length, embedding):\n",
    "    inputs_embedded = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    cell = tf.nn.rnn_cell.GRUCell(hidden_dim, name=cell_name)\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(\n",
    "        cell=cell,\n",
    "        inputs=inputs_embedded,\n",
    "        sequence_length=inputs_length,\n",
    "        dtype=tf.float32,\n",
    "        scope='encoder'\n",
    "    )\n",
    "    return final_state\n",
    "\n",
    "def create_trainer_decoder(thought_vector, embedding, inputs, inputs_length):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(hidden_dim, name=cell_name)\n",
    "    output_layer = tf.layers.Dense(vocab_size, use_bias=False, name=out_layer_name)\n",
    "    inputs_embedded = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        inputs=inputs_embedded,\n",
    "        sequence_length=inputs_length,\n",
    "    )\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(cell, helper, thought_vector, output_layer=output_layer)\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, swap_memory=True, scope=decoder_scope)\n",
    "    return outputs.rnn_output\n",
    "\n",
    "def create_generation_decoder(thought_vector, embedding):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(hidden_dim, name=cell_name)\n",
    "    output_layer = tf.layers.Dense(vocab_size, use_bias=False, name=out_layer_name)\n",
    "    start_tokens = tf.ones([batch_size], tf.int32)  # BOS==1\n",
    "    end_token = 2  # EOS==2\n",
    "    tiled_thought_vector = tf.contrib.seq2seq.tile_batch(thought_vector, multiplier=beam_width)\n",
    "\n",
    "    decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "        cell=cell,\n",
    "        embedding=embedding,\n",
    "        start_tokens=start_tokens,\n",
    "        end_token=end_token,\n",
    "        initial_state=tiled_thought_vector,\n",
    "        beam_width=beam_width,\n",
    "        output_layer=output_layer,\n",
    "    )\n",
    "\n",
    "    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        decoder=decoder, maximum_iterations=max_len, scope=decoder_scope\n",
    "    )\n",
    "    return decoder_outputs.predicted_ids\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    encoder_inputs = tf.ones(shape=[batch_size, max_len], dtype=tf.int32)\n",
    "    encoder_inputs_length = tf.ones(shape=[batch_size], dtype=tf.int32) * max_len\n",
    "    decoder_inputs = tf.ones(shape=[batch_size, max_len], dtype=tf.int32)\n",
    "    decoder_inputs_length = tf.ones(shape=[batch_size], dtype=tf.int32) * max_len\n",
    "\n",
    "    embedding = tf.Variable(tf.random_uniform([vocab_size, embedding_dim], -1.0, 1.0), dtype=tf.float32, name='embedding')\n",
    "    thought_vector = create_encoder(encoder_inputs, encoder_inputs_length, embedding)\n",
    "    \n",
    "    with tf.variable_scope('decoder') as scope:\n",
    "        train_outputs = create_trainer_decoder(\n",
    "            thought_vector,\n",
    "            embedding,\n",
    "            decoder_inputs,\n",
    "            decoder_inputs_length,\n",
    "        )\n",
    "        scope.reuse_variables()\n",
    "        generation_outputs = create_generation_decoder(\n",
    "            thought_vector,\n",
    "            embedding,\n",
    "        )\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_result, generation_result = sess.run([train_outputs, generation_outputs])\n",
    "    train_ids = np.argmax(train_result, axis=-1)\n",
    "    generation_ids = generation_result[:,:,0]\n",
    "    print(train_ids)\n",
    "    print(generation_ids)\n",
    "    show_variables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
